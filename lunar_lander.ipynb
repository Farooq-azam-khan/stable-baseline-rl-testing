{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gym \r\n",
        "from gym.wrappers import RecordVideo"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767612269
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'LunarLander-v2'"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767612423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_name)\r\n",
        "env = RecordVideo(env, f'{env_name}-video', episode_trigger=lambda _: True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/gym/wrappers/record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpucomputer/code/Users/fkhan/RL-reserach/LunarLander-v2-video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n  logger.warn(\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767613194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_environment():\r\n",
        "    episodes = 10\r\n",
        "    observation = env.reset()\r\n",
        "    for episode in range(episodes): \r\n",
        "        state = env.reset()\r\n",
        "        done = False \r\n",
        "        score = 0 \r\n",
        "        while not done: \r\n",
        "            action = env.action_space.sample()\r\n",
        "            observation, reward, done, info = env.step(action)\r\n",
        "            score += reward \r\n",
        "        print(f'Episode={episode+1} Score:{score}')\r\n",
        "    env.close()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767615267
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt install xvfb -y\r\n",
        "#!pip install pyvirtualdisplay\r\n",
        "#!pip install pyglet==1.5.27\r\n",
        "#!sudo apt-get install python-opengl"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767617027
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\r\n",
        "display = Display(visible=0, size=(1400, 900))\r\n",
        "display.start()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<pyvirtualdisplay.display.Display at 0x7f1bc1ce22e0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767620424
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_environment()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Episode=1 Score:-87.45999077745577\nEpisode=2 Score:-334.19090462218503\nEpisode=3 Score:-95.18830313569498\nEpisode=4 Score:-135.16209920346662\nEpisode=5 Score:-186.0419121110957\nEpisode=6 Score:-329.5537874637595\nEpisode=7 Score:-253.02823364676803\nEpisode=8 Score:-107.92308600360097\nEpisode=9 Score:-88.35739296488003\nEpisode=10 Score:-101.16333353862191\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767634112
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import A2C\r\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv "
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767648923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_name)\r\n",
        "model_name = 'a2c'\r\n",
        "model = A2C('MlpPolicy', env, verbose=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767662923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=90000)\r\n",
        "model.save(f\"{env_name}-{model_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 117      |\n|    ep_rew_mean        | -446     |\n| time/                 |          |\n|    fps                | 262      |\n|    iterations         | 100      |\n|    time_elapsed       | 1        |\n|    total_timesteps    | 500      |\n| train/                |          |\n|    entropy_loss       | -0.949   |\n|    explained_variance | 0.00841  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 99       |\n|    policy_loss        | -2.16    |\n|    value_loss         | 17.1     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 113      |\n|    ep_rew_mean        | -531     |\n| time/                 |          |\n|    fps                | 296      |\n|    iterations         | 200      |\n|    time_elapsed       | 3        |\n|    total_timesteps    | 1000     |\n| train/                |          |\n|    entropy_loss       | -1.12    |\n|    explained_variance | 8.82e-06 |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 199      |\n|    policy_loss        | -16.9    |\n|    value_loss         | 722      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 106      |\n|    ep_rew_mean        | -537     |\n| time/                 |          |\n|    fps                | 310      |\n|    iterations         | 300      |\n|    time_elapsed       | 4        |\n|    total_timesteps    | 1500     |\n| train/                |          |\n|    entropy_loss       | -1.3     |\n|    explained_variance | 1.42e-05 |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 299      |\n|    policy_loss        | -19.9    |\n|    value_loss         | 284      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 111      |\n|    ep_rew_mean        | -541     |\n| time/                 |          |\n|    fps                | 319      |\n|    iterations         | 400      |\n|    time_elapsed       | 6        |\n|    total_timesteps    | 2000     |\n| train/                |          |\n|    entropy_loss       | -1.38    |\n|    explained_variance | 9.24e-06 |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 399      |\n|    policy_loss        | -16      |\n|    value_loss         | 193      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 113      |\n|    ep_rew_mean        | -520     |\n| time/                 |          |\n|    fps                | 327      |\n|    iterations         | 500      |\n|    time_elapsed       | 7        |\n|    total_timesteps    | 2500     |\n| train/                |          |\n|    entropy_loss       | -1.15    |\n|    explained_variance | -0.0111  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 499      |\n|    policy_loss        | 0.931    |\n|    value_loss         | 2.44     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 109      |\n|    ep_rew_mean        | -469     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 600      |\n|    time_elapsed       | 9        |\n|    total_timesteps    | 3000     |\n| train/                |          |\n|    entropy_loss       | -1.37    |\n|    explained_variance | -0.0012  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 599      |\n|    policy_loss        | -15.3    |\n|    value_loss         | 139      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 109      |\n|    ep_rew_mean        | -423     |\n| time/                 |          |\n|    fps                | 334      |\n|    iterations         | 700      |\n|    time_elapsed       | 10       |\n|    total_timesteps    | 3500     |\n| train/                |          |\n|    entropy_loss       | -1.28    |\n|    explained_variance | 0.16     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 699      |\n|    policy_loss        | -5.85    |\n|    value_loss         | 28.9     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 113      |\n|    ep_rew_mean        | -408     |\n| time/                 |          |\n|    fps                | 337      |\n|    iterations         | 800      |\n|    time_elapsed       | 11       |\n|    total_timesteps    | 4000     |\n| train/                |          |\n|    entropy_loss       | -0.819   |\n|    explained_variance | -0.862   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 799      |\n|    policy_loss        | -3.87    |\n|    value_loss         | 19.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 118      |\n|    ep_rew_mean        | -410     |\n| time/                 |          |\n|    fps                | 338      |\n|    iterations         | 900      |\n|    time_elapsed       | 13       |\n|    total_timesteps    | 4500     |\n| train/                |          |\n|    entropy_loss       | -1.31    |\n|    explained_variance | -0.00419 |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 899      |\n|    policy_loss        | 3.64     |\n|    value_loss         | 9.27     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 123      |\n|    ep_rew_mean        | -405     |\n| time/                 |          |\n|    fps                | 338      |\n|    iterations         | 1000     |\n|    time_elapsed       | 14       |\n|    total_timesteps    | 5000     |\n| train/                |          |\n|    entropy_loss       | -0.69    |\n|    explained_variance | 0.0223   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 999      |\n|    policy_loss        | -5.51    |\n|    value_loss         | 199      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 123      |\n|    ep_rew_mean        | -406     |\n| time/                 |          |\n|    fps                | 337      |\n|    iterations         | 1100     |\n|    time_elapsed       | 16       |\n|    total_timesteps    | 5500     |\n| train/                |          |\n|    entropy_loss       | -1.24    |\n|    explained_variance | 0.0216   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1099     |\n|    policy_loss        | 0.688    |\n|    value_loss         | 26.3     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 123      |\n|    ep_rew_mean        | -406     |\n| time/                 |          |\n|    fps                | 327      |\n|    iterations         | 1200     |\n|    time_elapsed       | 18       |\n|    total_timesteps    | 6000     |\n| train/                |          |\n|    entropy_loss       | -0.63    |\n|    explained_variance | -0.168   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1199     |\n|    policy_loss        | -0.0198  |\n|    value_loss         | 0.0432   |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 149      |\n|    ep_rew_mean        | -392     |\n| time/                 |          |\n|    fps                | 327      |\n|    iterations         | 1300     |\n|    time_elapsed       | 19       |\n|    total_timesteps    | 6500     |\n| train/                |          |\n|    entropy_loss       | -0.998   |\n|    explained_variance | -0.661   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1299     |\n|    policy_loss        | 6.94     |\n|    value_loss         | 69.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 150      |\n|    ep_rew_mean        | -369     |\n| time/                 |          |\n|    fps                | 328      |\n|    iterations         | 1400     |\n|    time_elapsed       | 21       |\n|    total_timesteps    | 7000     |\n| train/                |          |\n|    entropy_loss       | -1.12    |\n|    explained_variance | 0.0232   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1399     |\n|    policy_loss        | -4.4     |\n|    value_loss         | 26       |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 153      |\n|    ep_rew_mean        | -366     |\n| time/                 |          |\n|    fps                | 328      |\n|    iterations         | 1500     |\n|    time_elapsed       | 22       |\n|    total_timesteps    | 7500     |\n| train/                |          |\n|    entropy_loss       | -0.677   |\n|    explained_variance | -0.249   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1499     |\n|    policy_loss        | -0.0149  |\n|    value_loss         | 0.0589   |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 162      |\n|    ep_rew_mean        | -349     |\n| time/                 |          |\n|    fps                | 327      |\n|    iterations         | 1600     |\n|    time_elapsed       | 24       |\n|    total_timesteps    | 8000     |\n| train/                |          |\n|    entropy_loss       | -1.06    |\n|    explained_variance | -0.169   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1599     |\n|    policy_loss        | 2.31     |\n|    value_loss         | 25.9     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 163      |\n|    ep_rew_mean        | -332     |\n| time/                 |          |\n|    fps                | 327      |\n|    iterations         | 1700     |\n|    time_elapsed       | 25       |\n|    total_timesteps    | 8500     |\n| train/                |          |\n|    entropy_loss       | -0.848   |\n|    explained_variance | 0.0347   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1699     |\n|    policy_loss        | 0.867    |\n|    value_loss         | 5.28     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 163      |\n|    ep_rew_mean        | -320     |\n| time/                 |          |\n|    fps                | 329      |\n|    iterations         | 1800     |\n|    time_elapsed       | 27       |\n|    total_timesteps    | 9000     |\n| train/                |          |\n|    entropy_loss       | -0.469   |\n|    explained_variance | -0.585   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1799     |\n|    policy_loss        | -0.375   |\n|    value_loss         | 11       |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 164      |\n|    ep_rew_mean        | -313     |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 1900     |\n|    time_elapsed       | 28       |\n|    total_timesteps    | 9500     |\n| train/                |          |\n|    entropy_loss       | -0.855   |\n|    explained_variance | -0.278   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1899     |\n|    policy_loss        | 0.143    |\n|    value_loss         | 0.949    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 163      |\n|    ep_rew_mean        | -297     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 2000     |\n|    time_elapsed       | 30       |\n|    total_timesteps    | 10000    |\n| train/                |          |\n|    entropy_loss       | -1.16    |\n|    explained_variance | 0.00535  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 1999     |\n|    policy_loss        | 3.5      |\n|    value_loss         | 19.5     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 164      |\n|    ep_rew_mean        | -286     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 2100     |\n|    time_elapsed       | 31       |\n|    total_timesteps    | 10500    |\n| train/                |          |\n|    entropy_loss       | -1.21    |\n|    explained_variance | 0.0332   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2099     |\n|    policy_loss        | -1.42    |\n|    value_loss         | 4.64     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 166      |\n|    ep_rew_mean        | -282     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 2200     |\n|    time_elapsed       | 33       |\n|    total_timesteps    | 11000    |\n| train/                |          |\n|    entropy_loss       | -0.84    |\n|    explained_variance | -0.319   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2199     |\n|    policy_loss        | 3.47     |\n|    value_loss         | 37.1     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 166      |\n|    ep_rew_mean        | -280     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 2300     |\n|    time_elapsed       | 34       |\n|    total_timesteps    | 11500    |\n| train/                |          |\n|    entropy_loss       | -0.659   |\n|    explained_variance | -0.119   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2299     |\n|    policy_loss        | 5.32     |\n|    value_loss         | 119      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 169      |\n|    ep_rew_mean        | -275     |\n| time/                 |          |\n|    fps                | 329      |\n|    iterations         | 2400     |\n|    time_elapsed       | 36       |\n|    total_timesteps    | 12000    |\n| train/                |          |\n|    entropy_loss       | -0.435   |\n|    explained_variance | -1.13    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2399     |\n|    policy_loss        | 1.61     |\n|    value_loss         | 9.79     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 169      |\n|    ep_rew_mean        | -269     |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 2500     |\n|    time_elapsed       | 37       |\n|    total_timesteps    | 12500    |\n| train/                |          |\n|    entropy_loss       | -0.567   |\n|    explained_variance | 0.204    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2499     |\n|    policy_loss        | -2.35    |\n|    value_loss         | 8.07     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 171      |\n|    ep_rew_mean        | -265     |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 2600     |\n|    time_elapsed       | 39       |\n|    total_timesteps    | 13000    |\n| train/                |          |\n|    entropy_loss       | -0.202   |\n|    explained_variance | -0.314   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2599     |\n|    policy_loss        | 0.0796   |\n|    value_loss         | 9.37     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 172      |\n|    ep_rew_mean        | -260     |\n| time/                 |          |\n|    fps                | 329      |\n|    iterations         | 2700     |\n|    time_elapsed       | 40       |\n|    total_timesteps    | 13500    |\n| train/                |          |\n|    entropy_loss       | -0.684   |\n|    explained_variance | -1.29    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2699     |\n|    policy_loss        | 6.51     |\n|    value_loss         | 133      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 172      |\n|    ep_rew_mean        | -256     |\n| time/                 |          |\n|    fps                | 329      |\n|    iterations         | 2800     |\n|    time_elapsed       | 42       |\n|    total_timesteps    | 14000    |\n| train/                |          |\n|    entropy_loss       | -0.862   |\n|    explained_variance | 0.081    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2799     |\n|    policy_loss        | 0.904    |\n|    value_loss         | 6.67     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 173      |\n|    ep_rew_mean        | -249     |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 2900     |\n|    time_elapsed       | 43       |\n|    total_timesteps    | 14500    |\n| train/                |          |\n|    entropy_loss       | -0.623   |\n|    explained_variance | -1.96    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2899     |\n|    policy_loss        | -65.8    |\n|    value_loss         | 7.58e+03 |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 173      |\n|    ep_rew_mean        | -245     |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 3000     |\n|    time_elapsed       | 45       |\n|    total_timesteps    | 15000    |\n| train/                |          |\n|    entropy_loss       | -0.675   |\n|    explained_variance | -1.08    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 2999     |\n|    policy_loss        | 8.8      |\n|    value_loss         | 265      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 174      |\n|    ep_rew_mean        | -243     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3100     |\n|    time_elapsed       | 46       |\n|    total_timesteps    | 15500    |\n| train/                |          |\n|    entropy_loss       | -0.668   |\n|    explained_variance | 0.0303   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3099     |\n|    policy_loss        | 3.31     |\n|    value_loss         | 59.1     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 176      |\n|    ep_rew_mean        | -241     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3200     |\n|    time_elapsed       | 48       |\n|    total_timesteps    | 16000    |\n| train/                |          |\n|    entropy_loss       | -0.672   |\n|    explained_variance | -2.43    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3199     |\n|    policy_loss        | 6.35     |\n|    value_loss         | 111      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 176      |\n|    ep_rew_mean        | -237     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3300     |\n|    time_elapsed       | 49       |\n|    total_timesteps    | 16500    |\n| train/                |          |\n|    entropy_loss       | -0.775   |\n|    explained_variance | 0.0991   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3299     |\n|    policy_loss        | 4.22     |\n|    value_loss         | 59.7     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 177      |\n|    ep_rew_mean        | -235     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3400     |\n|    time_elapsed       | 51       |\n|    total_timesteps    | 17000    |\n| train/                |          |\n|    entropy_loss       | -0.316   |\n|    explained_variance | 0.12     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3399     |\n|    policy_loss        | 0.0363   |\n|    value_loss         | 0.25     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 180      |\n|    ep_rew_mean        | -227     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3500     |\n|    time_elapsed       | 52       |\n|    total_timesteps    | 17500    |\n| train/                |          |\n|    entropy_loss       | -0.844   |\n|    explained_variance | 0.667    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3499     |\n|    policy_loss        | -0.413   |\n|    value_loss         | 1.03     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 181      |\n|    ep_rew_mean        | -222     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3600     |\n|    time_elapsed       | 54       |\n|    total_timesteps    | 18000    |\n| train/                |          |\n|    entropy_loss       | -0.553   |\n|    explained_variance | -0.164   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3599     |\n|    policy_loss        | 1.31     |\n|    value_loss         | 6.75     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 181      |\n|    ep_rew_mean        | -216     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 3700     |\n|    time_elapsed       | 55       |\n|    total_timesteps    | 18500    |\n| train/                |          |\n|    entropy_loss       | -1.21    |\n|    explained_variance | -4.22    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3699     |\n|    policy_loss        | 3.93     |\n|    value_loss         | 16.7     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 185      |\n|    ep_rew_mean        | -205     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3800     |\n|    time_elapsed       | 57       |\n|    total_timesteps    | 19000    |\n| train/                |          |\n|    entropy_loss       | -0.797   |\n|    explained_variance | 0.763    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3799     |\n|    policy_loss        | 4.27     |\n|    value_loss         | 108      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 186      |\n|    ep_rew_mean        | -187     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 3900     |\n|    time_elapsed       | 58       |\n|    total_timesteps    | 19500    |\n| train/                |          |\n|    entropy_loss       | -0.713   |\n|    explained_variance | 0.137    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3899     |\n|    policy_loss        | 6.45     |\n|    value_loss         | 116      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 189      |\n|    ep_rew_mean        | -172     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 4000     |\n|    time_elapsed       | 60       |\n|    total_timesteps    | 20000    |\n| train/                |          |\n|    entropy_loss       | -1.11    |\n|    explained_variance | 0.762    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 3999     |\n|    policy_loss        | -1.88    |\n|    value_loss         | 7.69     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 192      |\n|    ep_rew_mean        | -164     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 4100     |\n|    time_elapsed       | 61       |\n|    total_timesteps    | 20500    |\n| train/                |          |\n|    entropy_loss       | -0.683   |\n|    explained_variance | 0.889    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4099     |\n|    policy_loss        | 1.07     |\n|    value_loss         | 3.27     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 194      |\n|    ep_rew_mean        | -148     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 4200     |\n|    time_elapsed       | 63       |\n|    total_timesteps    | 21000    |\n| train/                |          |\n|    entropy_loss       | -0.287   |\n|    explained_variance | -0.104   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4199     |\n|    policy_loss        | -6.58    |\n|    value_loss         | 8.07e+03 |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 195      |\n|    ep_rew_mean        | -137     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 4300     |\n|    time_elapsed       | 64       |\n|    total_timesteps    | 21500    |\n| train/                |          |\n|    entropy_loss       | -0.77    |\n|    explained_variance | 0.887    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4299     |\n|    policy_loss        | 1.54     |\n|    value_loss         | 4.53     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 197      |\n|    ep_rew_mean        | -125     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 4400     |\n|    time_elapsed       | 66       |\n|    total_timesteps    | 22000    |\n| train/                |          |\n|    entropy_loss       | -0.55    |\n|    explained_variance | 0.785    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4399     |\n|    policy_loss        | -2.51    |\n|    value_loss         | 9.41     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 199      |\n|    ep_rew_mean        | -119     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 4500     |\n|    time_elapsed       | 67       |\n|    total_timesteps    | 22500    |\n| train/                |          |\n|    entropy_loss       | -0.203   |\n|    explained_variance | -39.4    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4499     |\n|    policy_loss        | -0.18    |\n|    value_loss         | 18.9     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 203      |\n|    ep_rew_mean        | -108     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 4600     |\n|    time_elapsed       | 69       |\n|    total_timesteps    | 23000    |\n| train/                |          |\n|    entropy_loss       | -0.315   |\n|    explained_variance | 0.803    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4599     |\n|    policy_loss        | -3.33    |\n|    value_loss         | 22.9     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 205      |\n|    ep_rew_mean        | -101     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 4700     |\n|    time_elapsed       | 70       |\n|    total_timesteps    | 23500    |\n| train/                |          |\n|    entropy_loss       | -0.626   |\n|    explained_variance | -5.72    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4699     |\n|    policy_loss        | -5.37    |\n|    value_loss         | 126      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 207      |\n|    ep_rew_mean        | -97.9    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 4800     |\n|    time_elapsed       | 72       |\n|    total_timesteps    | 24000    |\n| train/                |          |\n|    entropy_loss       | -1.21    |\n|    explained_variance | 0.398    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4799     |\n|    policy_loss        | -2.42    |\n|    value_loss         | 3.7      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 208      |\n|    ep_rew_mean        | -90.4    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 4900     |\n|    time_elapsed       | 73       |\n|    total_timesteps    | 24500    |\n| train/                |          |\n|    entropy_loss       | -1.19    |\n|    explained_variance | 0.38     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4899     |\n|    policy_loss        | -4.02    |\n|    value_loss         | 14.3     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 212      |\n|    ep_rew_mean        | -86.7    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 5000     |\n|    time_elapsed       | 75       |\n|    total_timesteps    | 25000    |\n| train/                |          |\n|    entropy_loss       | -0.694   |\n|    explained_variance | 0.361    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 4999     |\n|    policy_loss        | 4.42     |\n|    value_loss         | 84.7     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 212      |\n|    ep_rew_mean        | -74.8    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 5100     |\n|    time_elapsed       | 76       |\n|    total_timesteps    | 25500    |\n| train/                |          |\n|    entropy_loss       | -0.876   |\n|    explained_variance | 0.841    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5099     |\n|    policy_loss        | 0.436    |\n|    value_loss         | 1.01     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 215      |\n|    ep_rew_mean        | -65.9    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 5200     |\n|    time_elapsed       | 78       |\n|    total_timesteps    | 26000    |\n| train/                |          |\n|    entropy_loss       | -0.286   |\n|    explained_variance | 0.796    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5199     |\n|    policy_loss        | 1.37     |\n|    value_loss         | 8.19     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 213      |\n|    ep_rew_mean        | -57      |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 5300     |\n|    time_elapsed       | 79       |\n|    total_timesteps    | 26500    |\n| train/                |          |\n|    entropy_loss       | -0.675   |\n|    explained_variance | 0.977    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5299     |\n|    policy_loss        | 0.0277   |\n|    value_loss         | 0.237    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 203      |\n|    ep_rew_mean        | -56.3    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 5400     |\n|    time_elapsed       | 81       |\n|    total_timesteps    | 27000    |\n| train/                |          |\n|    entropy_loss       | -0.788   |\n|    explained_variance | 0.63     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5399     |\n|    policy_loss        | 4.23     |\n|    value_loss         | 83.2     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 202      |\n|    ep_rew_mean        | -52.7    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 5500     |\n|    time_elapsed       | 82       |\n|    total_timesteps    | 27500    |\n| train/                |          |\n|    entropy_loss       | -0.97    |\n|    explained_variance | 0.848    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5499     |\n|    policy_loss        | -0.697   |\n|    value_loss         | 1.08     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 202      |\n|    ep_rew_mean        | -52.7    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 5600     |\n|    time_elapsed       | 84       |\n|    total_timesteps    | 28000    |\n| train/                |          |\n|    entropy_loss       | -0.349   |\n|    explained_variance | -0.666   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5599     |\n|    policy_loss        | 0.00533  |\n|    value_loss         | 0.0144   |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 202      |\n|    ep_rew_mean        | -52.4    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 5700     |\n|    time_elapsed       | 86       |\n|    total_timesteps    | 28500    |\n| train/                |          |\n|    entropy_loss       | -1.18    |\n|    explained_variance | 0.967    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5699     |\n|    policy_loss        | 1.3      |\n|    value_loss         | 2.04     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 204      |\n|    ep_rew_mean        | -49.6    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 5800     |\n|    time_elapsed       | 87       |\n|    total_timesteps    | 29000    |\n| train/                |          |\n|    entropy_loss       | -0.622   |\n|    explained_variance | 0.475    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5799     |\n|    policy_loss        | -1.05    |\n|    value_loss         | 7.38     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 206      |\n|    ep_rew_mean        | -43.6    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 5900     |\n|    time_elapsed       | 89       |\n|    total_timesteps    | 29500    |\n| train/                |          |\n|    entropy_loss       | -0.443   |\n|    explained_variance | -4.83    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5899     |\n|    policy_loss        | -0.942   |\n|    value_loss         | 42.5     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 208      |\n|    ep_rew_mean        | -40.3    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6000     |\n|    time_elapsed       | 90       |\n|    total_timesteps    | 30000    |\n| train/                |          |\n|    entropy_loss       | -0.328   |\n|    explained_variance | 0.178    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 5999     |\n|    policy_loss        | 3.7      |\n|    value_loss         | 180      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 208      |\n|    ep_rew_mean        | -39.2    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 6100     |\n|    time_elapsed       | 92       |\n|    total_timesteps    | 30500    |\n| train/                |          |\n|    entropy_loss       | -0.856   |\n|    explained_variance | -0.25    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6099     |\n|    policy_loss        | -2.14    |\n|    value_loss         | 18.2     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 208      |\n|    ep_rew_mean        | -38      |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6200     |\n|    time_elapsed       | 93       |\n|    total_timesteps    | 31000    |\n| train/                |          |\n|    entropy_loss       | -0.524   |\n|    explained_variance | 0.287    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6199     |\n|    policy_loss        | 3.47     |\n|    value_loss         | 29.5     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 210      |\n|    ep_rew_mean        | -34.2    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6300     |\n|    time_elapsed       | 95       |\n|    total_timesteps    | 31500    |\n| train/                |          |\n|    entropy_loss       | -0.634   |\n|    explained_variance | 0.593    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6299     |\n|    policy_loss        | 1.1      |\n|    value_loss         | 5.21     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 209      |\n|    ep_rew_mean        | -32      |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6400     |\n|    time_elapsed       | 96       |\n|    total_timesteps    | 32000    |\n| train/                |          |\n|    entropy_loss       | -0.576   |\n|    explained_variance | 0.805    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6399     |\n|    policy_loss        | 3.79     |\n|    value_loss         | 39       |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 209      |\n|    ep_rew_mean        | -30.5    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6500     |\n|    time_elapsed       | 98       |\n|    total_timesteps    | 32500    |\n| train/                |          |\n|    entropy_loss       | -0.625   |\n|    explained_variance | -0.064   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6499     |\n|    policy_loss        | 5.66     |\n|    value_loss         | 82.7     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 209      |\n|    ep_rew_mean        | -23.4    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6600     |\n|    time_elapsed       | 99       |\n|    total_timesteps    | 33000    |\n| train/                |          |\n|    entropy_loss       | -0.694   |\n|    explained_variance | 0.725    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6599     |\n|    policy_loss        | 0.721    |\n|    value_loss         | 3.41     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 209      |\n|    ep_rew_mean        | -22.1    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 6700     |\n|    time_elapsed       | 101      |\n|    total_timesteps    | 33500    |\n| train/                |          |\n|    entropy_loss       | -1.2     |\n|    explained_variance | -0.153   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6699     |\n|    policy_loss        | -1.47    |\n|    value_loss         | 8.55     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 212      |\n|    ep_rew_mean        | -19.4    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 6800     |\n|    time_elapsed       | 102      |\n|    total_timesteps    | 34000    |\n| train/                |          |\n|    entropy_loss       | -0.34    |\n|    explained_variance | 0.16     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6799     |\n|    policy_loss        | -0.00348 |\n|    value_loss         | 0.0018   |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 213      |\n|    ep_rew_mean        | -12.9    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 6900     |\n|    time_elapsed       | 104      |\n|    total_timesteps    | 34500    |\n| train/                |          |\n|    entropy_loss       | -0.142   |\n|    explained_variance | -4.83    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6899     |\n|    policy_loss        | 0.118    |\n|    value_loss         | 28       |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 215      |\n|    ep_rew_mean        | -9.49    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 7000     |\n|    time_elapsed       | 105      |\n|    total_timesteps    | 35000    |\n| train/                |          |\n|    entropy_loss       | -1.01    |\n|    explained_variance | 0.789    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 6999     |\n|    policy_loss        | -0.999   |\n|    value_loss         | 2.03     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 215      |\n|    ep_rew_mean        | -4.85    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 7100     |\n|    time_elapsed       | 107      |\n|    total_timesteps    | 35500    |\n| train/                |          |\n|    entropy_loss       | -0.509   |\n|    explained_variance | -0.00855 |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7099     |\n|    policy_loss        | 3.12     |\n|    value_loss         | 25.5     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 216      |\n|    ep_rew_mean        | -0.208   |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 7200     |\n|    time_elapsed       | 108      |\n|    total_timesteps    | 36000    |\n| train/                |          |\n|    entropy_loss       | -1.11    |\n|    explained_variance | 0.922    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7199     |\n|    policy_loss        | -0.28    |\n|    value_loss         | 0.112    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 217      |\n|    ep_rew_mean        | 0.551    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 7300     |\n|    time_elapsed       | 110      |\n|    total_timesteps    | 36500    |\n| train/                |          |\n|    entropy_loss       | -0.997   |\n|    explained_variance | 0.12     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7299     |\n|    policy_loss        | -1.43    |\n|    value_loss         | 4.11     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 217      |\n|    ep_rew_mean        | 2.72     |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 7400     |\n|    time_elapsed       | 111      |\n|    total_timesteps    | 37000    |\n| train/                |          |\n|    entropy_loss       | -1.24    |\n|    explained_variance | 0.925    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7399     |\n|    policy_loss        | 1.09     |\n|    value_loss         | 2.47     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 213      |\n|    ep_rew_mean        | 3.35     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 7500     |\n|    time_elapsed       | 112      |\n|    total_timesteps    | 37500    |\n| train/                |          |\n|    entropy_loss       | -1.09    |\n|    explained_variance | 0.63     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7499     |\n|    policy_loss        | 0.272    |\n|    value_loss         | 0.455    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 209      |\n|    ep_rew_mean        | 1.94     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 7600     |\n|    time_elapsed       | 114      |\n|    total_timesteps    | 38000    |\n| train/                |          |\n|    entropy_loss       | -0.617   |\n|    explained_variance | 0.626    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7599     |\n|    policy_loss        | 1.06     |\n|    value_loss         | 2.17     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 205      |\n|    ep_rew_mean        | 1.75     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 7700     |\n|    time_elapsed       | 115      |\n|    total_timesteps    | 38500    |\n| train/                |          |\n|    entropy_loss       | -1.23    |\n|    explained_variance | 0.962    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7699     |\n|    policy_loss        | -0.124   |\n|    value_loss         | 0.0866   |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 206      |\n|    ep_rew_mean        | 3.19     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 7800     |\n|    time_elapsed       | 117      |\n|    total_timesteps    | 39000    |\n| train/                |          |\n|    entropy_loss       | -1.02    |\n|    explained_variance | 0.921    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7799     |\n|    policy_loss        | 0.84     |\n|    value_loss         | 1.2      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 208      |\n|    ep_rew_mean        | 5.35     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 7900     |\n|    time_elapsed       | 118      |\n|    total_timesteps    | 39500    |\n| train/                |          |\n|    entropy_loss       | -1.14    |\n|    explained_variance | -4.47    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7899     |\n|    policy_loss        | 5.91     |\n|    value_loss         | 25.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 208      |\n|    ep_rew_mean        | 5.35     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8000     |\n|    time_elapsed       | 120      |\n|    total_timesteps    | 40000    |\n| train/                |          |\n|    entropy_loss       | -0.444   |\n|    explained_variance | -0.156   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 7999     |\n|    policy_loss        | -6.69    |\n|    value_loss         | 35.8     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 212      |\n|    ep_rew_mean        | 3.98     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8100     |\n|    time_elapsed       | 121      |\n|    total_timesteps    | 40500    |\n| train/                |          |\n|    entropy_loss       | -0.631   |\n|    explained_variance | -6.97    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8099     |\n|    policy_loss        | -0.248   |\n|    value_loss         | 8.49     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 216      |\n|    ep_rew_mean        | 6        |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8200     |\n|    time_elapsed       | 123      |\n|    total_timesteps    | 41000    |\n| train/                |          |\n|    entropy_loss       | -0.734   |\n|    explained_variance | -1.73    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8199     |\n|    policy_loss        | 1.5      |\n|    value_loss         | 2.1      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 218      |\n|    ep_rew_mean        | 7.66     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8300     |\n|    time_elapsed       | 124      |\n|    total_timesteps    | 41500    |\n| train/                |          |\n|    entropy_loss       | -0.964   |\n|    explained_variance | -1.43    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8299     |\n|    policy_loss        | -1.87    |\n|    value_loss         | 15.3     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 215      |\n|    ep_rew_mean        | 6.28     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8400     |\n|    time_elapsed       | 126      |\n|    total_timesteps    | 42000    |\n| train/                |          |\n|    entropy_loss       | -1.11    |\n|    explained_variance | 0.397    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8399     |\n|    policy_loss        | 1.38     |\n|    value_loss         | 1.51     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 214      |\n|    ep_rew_mean        | 5.23     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8500     |\n|    time_elapsed       | 127      |\n|    total_timesteps    | 42500    |\n| train/                |          |\n|    entropy_loss       | -0.663   |\n|    explained_variance | 0.811    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8499     |\n|    policy_loss        | 0.31     |\n|    value_loss         | 0.304    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 212      |\n|    ep_rew_mean        | 4.16     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8600     |\n|    time_elapsed       | 129      |\n|    total_timesteps    | 43000    |\n| train/                |          |\n|    entropy_loss       | -1.23    |\n|    explained_variance | 0.475    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8599     |\n|    policy_loss        | 2.35     |\n|    value_loss         | 11.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 213      |\n|    ep_rew_mean        | 4.49     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8700     |\n|    time_elapsed       | 130      |\n|    total_timesteps    | 43500    |\n| train/                |          |\n|    entropy_loss       | -0.166   |\n|    explained_variance | -0.278   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8699     |\n|    policy_loss        | 0.0305   |\n|    value_loss         | 0.705    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 214      |\n|    ep_rew_mean        | 4.82     |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8800     |\n|    time_elapsed       | 132      |\n|    total_timesteps    | 44000    |\n| train/                |          |\n|    entropy_loss       | -0.791   |\n|    explained_variance | -0.226   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8799     |\n|    policy_loss        | -1.34    |\n|    value_loss         | 9.48     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 217      |\n|    ep_rew_mean        | -0.31    |\n| time/                 |          |\n|    fps                | 332      |\n|    iterations         | 8900     |\n|    time_elapsed       | 133      |\n|    total_timesteps    | 44500    |\n| train/                |          |\n|    entropy_loss       | -1.15    |\n|    explained_variance | 0.748    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8899     |\n|    policy_loss        | -0.851   |\n|    value_loss         | 1.37     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 217      |\n|    ep_rew_mean        | -0.31    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 9000     |\n|    time_elapsed       | 135      |\n|    total_timesteps    | 45000    |\n| train/                |          |\n|    entropy_loss       | -0.944   |\n|    explained_variance | 0.34     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 8999     |\n|    policy_loss        | 0.758    |\n|    value_loss         | 1.95     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 222      |\n|    ep_rew_mean        | -1.11    |\n| time/                 |          |\n|    fps                | 331      |\n|    iterations         | 9100     |\n|    time_elapsed       | 137      |\n|    total_timesteps    | 45500    |\n| train/                |          |\n|    entropy_loss       | -0.872   |\n|    explained_variance | -0.263   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9099     |\n|    policy_loss        | 0.443    |\n|    value_loss         | 1.15     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 225      |\n|    ep_rew_mean        | -2.77    |\n| time/                 |          |\n|    fps                | 330      |\n|    iterations         | 9200     |\n|    time_elapsed       | 139      |\n|    total_timesteps    | 46000    |\n| train/                |          |\n|    entropy_loss       | -0.879   |\n|    explained_variance | -0.0533  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9199     |\n|    policy_loss        | -0.72    |\n|    value_loss         | 3.53     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 233      |\n|    ep_rew_mean        | -0.265   |\n| time/                 |          |\n|    fps                | 328      |\n|    iterations         | 9300     |\n|    time_elapsed       | 141      |\n|    total_timesteps    | 46500    |\n| train/                |          |\n|    entropy_loss       | -0.103   |\n|    explained_variance | -0.989   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9299     |\n|    policy_loss        | 2.44     |\n|    value_loss         | 5.93e+03 |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 233      |\n|    ep_rew_mean        | -0.265   |\n| time/                 |          |\n|    fps                | 328      |\n|    iterations         | 9400     |\n|    time_elapsed       | 143      |\n|    total_timesteps    | 47000    |\n| train/                |          |\n|    entropy_loss       | -1.04    |\n|    explained_variance | 0.862    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9399     |\n|    policy_loss        | 0.0714   |\n|    value_loss         | 0.51     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 240      |\n|    ep_rew_mean        | 0.74     |\n| time/                 |          |\n|    fps                | 327      |\n|    iterations         | 9500     |\n|    time_elapsed       | 145      |\n|    total_timesteps    | 47500    |\n| train/                |          |\n|    entropy_loss       | -1.06    |\n|    explained_variance | 0.651    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9499     |\n|    policy_loss        | -1.64    |\n|    value_loss         | 1.78     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 240      |\n|    ep_rew_mean        | 0.74     |\n| time/                 |          |\n|    fps                | 326      |\n|    iterations         | 9600     |\n|    time_elapsed       | 146      |\n|    total_timesteps    | 48000    |\n| train/                |          |\n|    entropy_loss       | -1.2     |\n|    explained_variance | 0.943    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9599     |\n|    policy_loss        | 0.246    |\n|    value_loss         | 0.159    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 248      |\n|    ep_rew_mean        | 2.03     |\n| time/                 |          |\n|    fps                | 326      |\n|    iterations         | 9700     |\n|    time_elapsed       | 148      |\n|    total_timesteps    | 48500    |\n| train/                |          |\n|    entropy_loss       | -0.57    |\n|    explained_variance | 0.8      |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9699     |\n|    policy_loss        | -1.43    |\n|    value_loss         | 1.58     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 248      |\n|    ep_rew_mean        | 2.03     |\n| time/                 |          |\n|    fps                | 325      |\n|    iterations         | 9800     |\n|    time_elapsed       | 150      |\n|    total_timesteps    | 49000    |\n| train/                |          |\n|    entropy_loss       | -0.74    |\n|    explained_variance | 0.214    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9799     |\n|    policy_loss        | -1.82    |\n|    value_loss         | 7.72     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 255      |\n|    ep_rew_mean        | 1.46     |\n| time/                 |          |\n|    fps                | 324      |\n|    iterations         | 9900     |\n|    time_elapsed       | 152      |\n|    total_timesteps    | 49500    |\n| train/                |          |\n|    entropy_loss       | -0.413   |\n|    explained_variance | 0.854    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9899     |\n|    policy_loss        | -0.347   |\n|    value_loss         | 6.69     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 255      |\n|    ep_rew_mean        | 1.46     |\n| time/                 |          |\n|    fps                | 323      |\n|    iterations         | 10000    |\n|    time_elapsed       | 154      |\n|    total_timesteps    | 50000    |\n| train/                |          |\n|    entropy_loss       | -0.0349  |\n|    explained_variance | -0.0421  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 9999     |\n|    policy_loss        | 0.000261 |\n|    value_loss         | 0.00278  |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 260      |\n|    ep_rew_mean        | 0.0882   |\n| time/                 |          |\n|    fps                | 323      |\n|    iterations         | 10100    |\n|    time_elapsed       | 156      |\n|    total_timesteps    | 50500    |\n| train/                |          |\n|    entropy_loss       | -0.636   |\n|    explained_variance | 0.423    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10099    |\n|    policy_loss        | 3.15     |\n|    value_loss         | 14.6     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 260      |\n|    ep_rew_mean        | 0.0882   |\n| time/                 |          |\n|    fps                | 322      |\n|    iterations         | 10200    |\n|    time_elapsed       | 157      |\n|    total_timesteps    | 51000    |\n| train/                |          |\n|    entropy_loss       | -1.1     |\n|    explained_variance | -0.55    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10199    |\n|    policy_loss        | 3.36     |\n|    value_loss         | 19.2     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 268      |\n|    ep_rew_mean        | -1.04    |\n| time/                 |          |\n|    fps                | 322      |\n|    iterations         | 10300    |\n|    time_elapsed       | 159      |\n|    total_timesteps    | 51500    |\n| train/                |          |\n|    entropy_loss       | -0.909   |\n|    explained_variance | -0.148   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10299    |\n|    policy_loss        | 1.79     |\n|    value_loss         | 7.92     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 268      |\n|    ep_rew_mean        | -1.04    |\n| time/                 |          |\n|    fps                | 320      |\n|    iterations         | 10400    |\n|    time_elapsed       | 161      |\n|    total_timesteps    | 52000    |\n| train/                |          |\n|    entropy_loss       | -1.11    |\n|    explained_variance | -3.57    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10399    |\n|    policy_loss        | 1.55     |\n|    value_loss         | 2.11     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 278      |\n|    ep_rew_mean        | -0.549   |\n| time/                 |          |\n|    fps                | 320      |\n|    iterations         | 10500    |\n|    time_elapsed       | 163      |\n|    total_timesteps    | 52500    |\n| train/                |          |\n|    entropy_loss       | -0.437   |\n|    explained_variance | 0.968    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10499    |\n|    policy_loss        | -0.0445  |\n|    value_loss         | 0.095    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 278      |\n|    ep_rew_mean        | -0.549   |\n| time/                 |          |\n|    fps                | 319      |\n|    iterations         | 10600    |\n|    time_elapsed       | 165      |\n|    total_timesteps    | 53000    |\n| train/                |          |\n|    entropy_loss       | -1.07    |\n|    explained_variance | -1.13    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10599    |\n|    policy_loss        | 5.45     |\n|    value_loss         | 42.8     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 287      |\n|    ep_rew_mean        | -0.454   |\n| time/                 |          |\n|    fps                | 319      |\n|    iterations         | 10700    |\n|    time_elapsed       | 167      |\n|    total_timesteps    | 53500    |\n| train/                |          |\n|    entropy_loss       | -0.863   |\n|    explained_variance | 0.866    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10699    |\n|    policy_loss        | -1.25    |\n|    value_loss         | 2.54     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 287      |\n|    ep_rew_mean        | -0.454   |\n| time/                 |          |\n|    fps                | 317      |\n|    iterations         | 10800    |\n|    time_elapsed       | 170      |\n|    total_timesteps    | 54000    |\n| train/                |          |\n|    entropy_loss       | -0.823   |\n|    explained_variance | 0.645    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10799    |\n|    policy_loss        | 0.348    |\n|    value_loss         | 2.16     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 294      |\n|    ep_rew_mean        | -0.95    |\n| time/                 |          |\n|    fps                | 317      |\n|    iterations         | 10900    |\n|    time_elapsed       | 171      |\n|    total_timesteps    | 54500    |\n| train/                |          |\n|    entropy_loss       | -1.22    |\n|    explained_variance | 0.188    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10899    |\n|    policy_loss        | 0.435    |\n|    value_loss         | 0.405    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 294      |\n|    ep_rew_mean        | -0.95    |\n| time/                 |          |\n|    fps                | 316      |\n|    iterations         | 11000    |\n|    time_elapsed       | 173      |\n|    total_timesteps    | 55000    |\n| train/                |          |\n|    entropy_loss       | -0.892   |\n|    explained_variance | 0.583    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 10999    |\n|    policy_loss        | -0.277   |\n|    value_loss         | 1.1      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 301      |\n|    ep_rew_mean        | -4.13    |\n| time/                 |          |\n|    fps                | 316      |\n|    iterations         | 11100    |\n|    time_elapsed       | 175      |\n|    total_timesteps    | 55500    |\n| train/                |          |\n|    entropy_loss       | -1.18    |\n|    explained_variance | -0.537   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11099    |\n|    policy_loss        | 3.93     |\n|    value_loss         | 16.1     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 301      |\n|    ep_rew_mean        | -4.13    |\n| time/                 |          |\n|    fps                | 316      |\n|    iterations         | 11200    |\n|    time_elapsed       | 176      |\n|    total_timesteps    | 56000    |\n| train/                |          |\n|    entropy_loss       | -1.17    |\n|    explained_variance | 0.388    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11199    |\n|    policy_loss        | -0.345   |\n|    value_loss         | 0.848    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 309      |\n|    ep_rew_mean        | -5.45    |\n| time/                 |          |\n|    fps                | 316      |\n|    iterations         | 11300    |\n|    time_elapsed       | 178      |\n|    total_timesteps    | 56500    |\n| train/                |          |\n|    entropy_loss       | -0.855   |\n|    explained_variance | 0.711    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11299    |\n|    policy_loss        | 0.262    |\n|    value_loss         | 0.482    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 309      |\n|    ep_rew_mean        | -5.45    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 11400    |\n|    time_elapsed       | 180      |\n|    total_timesteps    | 57000    |\n| train/                |          |\n|    entropy_loss       | -1.15    |\n|    explained_variance | -0.604   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11399    |\n|    policy_loss        | 2.42     |\n|    value_loss         | 9.53     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 315      |\n|    ep_rew_mean        | -8.93    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 11500    |\n|    time_elapsed       | 182      |\n|    total_timesteps    | 57500    |\n| train/                |          |\n|    entropy_loss       | -0.365   |\n|    explained_variance | 0.394    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11499    |\n|    policy_loss        | -0.542   |\n|    value_loss         | 1.38     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 316      |\n|    ep_rew_mean        | -9.52    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 11600    |\n|    time_elapsed       | 183      |\n|    total_timesteps    | 58000    |\n| train/                |          |\n|    entropy_loss       | -1.17    |\n|    explained_variance | -0.521   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11599    |\n|    policy_loss        | 2.07     |\n|    value_loss         | 11       |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 322      |\n|    ep_rew_mean        | -8       |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 11700    |\n|    time_elapsed       | 185      |\n|    total_timesteps    | 58500    |\n| train/                |          |\n|    entropy_loss       | -0.845   |\n|    explained_variance | 0.726    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11699    |\n|    policy_loss        | 0.947    |\n|    value_loss         | 4.05     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 324      |\n|    ep_rew_mean        | -6.33    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 11800    |\n|    time_elapsed       | 187      |\n|    total_timesteps    | 59000    |\n| train/                |          |\n|    entropy_loss       | -1.08    |\n|    explained_variance | 0.486    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11799    |\n|    policy_loss        | 0.372    |\n|    value_loss         | 0.789    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 324      |\n|    ep_rew_mean        | -6.33    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 11900    |\n|    time_elapsed       | 188      |\n|    total_timesteps    | 59500    |\n| train/                |          |\n|    entropy_loss       | -1.24    |\n|    explained_variance | 0.134    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11899    |\n|    policy_loss        | -0.506   |\n|    value_loss         | 1.03     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 332      |\n|    ep_rew_mean        | -6.24    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 12000    |\n|    time_elapsed       | 190      |\n|    total_timesteps    | 60000    |\n| train/                |          |\n|    entropy_loss       | -1.03    |\n|    explained_variance | 0.342    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 11999    |\n|    policy_loss        | 1.03     |\n|    value_loss         | 3.81     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 332      |\n|    ep_rew_mean        | -6.24    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12100    |\n|    time_elapsed       | 192      |\n|    total_timesteps    | 60500    |\n| train/                |          |\n|    entropy_loss       | -0.934   |\n|    explained_variance | -0.216   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12099    |\n|    policy_loss        | 0.7      |\n|    value_loss         | 1.57     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 342      |\n|    ep_rew_mean        | -6.94    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12200    |\n|    time_elapsed       | 193      |\n|    total_timesteps    | 61000    |\n| train/                |          |\n|    entropy_loss       | -0.9     |\n|    explained_variance | 0.631    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12199    |\n|    policy_loss        | -1.34    |\n|    value_loss         | 7.32     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 342      |\n|    ep_rew_mean        | -5.23    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12300    |\n|    time_elapsed       | 195      |\n|    total_timesteps    | 61500    |\n| train/                |          |\n|    entropy_loss       | -0.282   |\n|    explained_variance | -0.00259 |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12299    |\n|    policy_loss        | -0.003   |\n|    value_loss         | 0.00243  |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 346      |\n|    ep_rew_mean        | -1.68    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12400    |\n|    time_elapsed       | 196      |\n|    total_timesteps    | 62000    |\n| train/                |          |\n|    entropy_loss       | -0.503   |\n|    explained_variance | 0.573    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12399    |\n|    policy_loss        | -5.08    |\n|    value_loss         | 44.1     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 346      |\n|    ep_rew_mean        | -1.68    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12500    |\n|    time_elapsed       | 198      |\n|    total_timesteps    | 62500    |\n| train/                |          |\n|    entropy_loss       | -0.815   |\n|    explained_variance | -1.74    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12499    |\n|    policy_loss        | -0.0549  |\n|    value_loss         | 0.873    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 347      |\n|    ep_rew_mean        | -2.12    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12600    |\n|    time_elapsed       | 200      |\n|    total_timesteps    | 63000    |\n| train/                |          |\n|    entropy_loss       | -0.789   |\n|    explained_variance | 0.349    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12599    |\n|    policy_loss        | -0.393   |\n|    value_loss         | 2.44     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 352      |\n|    ep_rew_mean        | 1.09     |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12700    |\n|    time_elapsed       | 201      |\n|    total_timesteps    | 63500    |\n| train/                |          |\n|    entropy_loss       | -0.529   |\n|    explained_variance | -13.9    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12699    |\n|    policy_loss        | 1.47     |\n|    value_loss         | 23.6     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 345      |\n|    ep_rew_mean        | -4.54    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12800    |\n|    time_elapsed       | 203      |\n|    total_timesteps    | 64000    |\n| train/                |          |\n|    entropy_loss       | -1.05    |\n|    explained_variance | -0.823   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12799    |\n|    policy_loss        | -0.101   |\n|    value_loss         | 0.346    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 345      |\n|    ep_rew_mean        | -6.3     |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 12900    |\n|    time_elapsed       | 204      |\n|    total_timesteps    | 64500    |\n| train/                |          |\n|    entropy_loss       | -1.07    |\n|    explained_variance | 0.741    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12899    |\n|    policy_loss        | 1.01     |\n|    value_loss         | 2.8      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 344      |\n|    ep_rew_mean        | -3.81    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 13000    |\n|    time_elapsed       | 206      |\n|    total_timesteps    | 65000    |\n| train/                |          |\n|    entropy_loss       | -0.423   |\n|    explained_variance | 0.903    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 12999    |\n|    policy_loss        | 5.12     |\n|    value_loss         | 205      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 345      |\n|    ep_rew_mean        | -5.01    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13100    |\n|    time_elapsed       | 207      |\n|    total_timesteps    | 65500    |\n| train/                |          |\n|    entropy_loss       | -0.326   |\n|    explained_variance | -4.49    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13099    |\n|    policy_loss        | 3.51     |\n|    value_loss         | 34.8     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 344      |\n|    ep_rew_mean        | -7.38    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13200    |\n|    time_elapsed       | 209      |\n|    total_timesteps    | 66000    |\n| train/                |          |\n|    entropy_loss       | -0.808   |\n|    explained_variance | 0.543    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13199    |\n|    policy_loss        | 3.25     |\n|    value_loss         | 3.08     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 344      |\n|    ep_rew_mean        | -5.37    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13300    |\n|    time_elapsed       | 210      |\n|    total_timesteps    | 66500    |\n| train/                |          |\n|    entropy_loss       | -0.713   |\n|    explained_variance | 0.0131   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13299    |\n|    policy_loss        | -0.0928  |\n|    value_loss         | 0.0347   |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 347      |\n|    ep_rew_mean        | -2.8     |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13400    |\n|    time_elapsed       | 212      |\n|    total_timesteps    | 67000    |\n| train/                |          |\n|    entropy_loss       | -0.629   |\n|    explained_variance | 0.266    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13399    |\n|    policy_loss        | -1.99    |\n|    value_loss         | 6.44     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 348      |\n|    ep_rew_mean        | -1.32    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13500    |\n|    time_elapsed       | 213      |\n|    total_timesteps    | 67500    |\n| train/                |          |\n|    entropy_loss       | -0.487   |\n|    explained_variance | 0.309    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13499    |\n|    policy_loss        | -0.62    |\n|    value_loss         | 2.22e+03 |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 347      |\n|    ep_rew_mean        | -4.71    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13600    |\n|    time_elapsed       | 215      |\n|    total_timesteps    | 68000    |\n| train/                |          |\n|    entropy_loss       | -0.548   |\n|    explained_variance | -0.524   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13599    |\n|    policy_loss        | -5.92    |\n|    value_loss         | 243      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 344      |\n|    ep_rew_mean        | -6.94    |\n| time/                 |          |\n|    fps                | 316      |\n|    iterations         | 13700    |\n|    time_elapsed       | 216      |\n|    total_timesteps    | 68500    |\n| train/                |          |\n|    entropy_loss       | -0.684   |\n|    explained_variance | -0.0287  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13699    |\n|    policy_loss        | -0.0063  |\n|    value_loss         | 0.00289  |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 344      |\n|    ep_rew_mean        | -6.94    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13800    |\n|    time_elapsed       | 218      |\n|    total_timesteps    | 69000    |\n| train/                |          |\n|    entropy_loss       | -0.602   |\n|    explained_variance | -0.0206  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13799    |\n|    policy_loss        | 0.0754   |\n|    value_loss         | 0.031    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 350      |\n|    ep_rew_mean        | -8.28    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 13900    |\n|    time_elapsed       | 219      |\n|    total_timesteps    | 69500    |\n| train/                |          |\n|    entropy_loss       | -0.939   |\n|    explained_variance | 0.506    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13899    |\n|    policy_loss        | 1.11     |\n|    value_loss         | 2.77     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 350      |\n|    ep_rew_mean        | -8.98    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 14000    |\n|    time_elapsed       | 221      |\n|    total_timesteps    | 70000    |\n| train/                |          |\n|    entropy_loss       | -0.909   |\n|    explained_variance | -0.976   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 13999    |\n|    policy_loss        | -0.679   |\n|    value_loss         | 3.24     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 355      |\n|    ep_rew_mean        | -6.87    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 14100    |\n|    time_elapsed       | 223      |\n|    total_timesteps    | 70500    |\n| train/                |          |\n|    entropy_loss       | -0.487   |\n|    explained_variance | 0.625    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14099    |\n|    policy_loss        | -2.84    |\n|    value_loss         | 20.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 358      |\n|    ep_rew_mean        | -7.46    |\n| time/                 |          |\n|    fps                | 315      |\n|    iterations         | 14200    |\n|    time_elapsed       | 225      |\n|    total_timesteps    | 71000    |\n| train/                |          |\n|    entropy_loss       | -1.09    |\n|    explained_variance | 0.315    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14199    |\n|    policy_loss        | -1.35    |\n|    value_loss         | 1.58     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 358      |\n|    ep_rew_mean        | -7.46    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 14300    |\n|    time_elapsed       | 227      |\n|    total_timesteps    | 71500    |\n| train/                |          |\n|    entropy_loss       | -0.508   |\n|    explained_variance | 0.359    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14299    |\n|    policy_loss        | 0.103    |\n|    value_loss         | 1.7      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 365      |\n|    ep_rew_mean        | -6.81    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 14400    |\n|    time_elapsed       | 228      |\n|    total_timesteps    | 72000    |\n| train/                |          |\n|    entropy_loss       | -1.05    |\n|    explained_variance | -0.519   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14399    |\n|    policy_loss        | -1.11    |\n|    value_loss         | 4        |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 365      |\n|    ep_rew_mean        | -6.81    |\n| time/                 |          |\n|    fps                | 314      |\n|    iterations         | 14500    |\n|    time_elapsed       | 230      |\n|    total_timesteps    | 72500    |\n| train/                |          |\n|    entropy_loss       | -0.534   |\n|    explained_variance | 0.625    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14499    |\n|    policy_loss        | 1.6      |\n|    value_loss         | 3.39     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 373      |\n|    ep_rew_mean        | -10.6    |\n| time/                 |          |\n|    fps                | 313      |\n|    iterations         | 14600    |\n|    time_elapsed       | 232      |\n|    total_timesteps    | 73000    |\n| train/                |          |\n|    entropy_loss       | -0.647   |\n|    explained_variance | -13      |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14599    |\n|    policy_loss        | 1.21     |\n|    value_loss         | 4.99     |\n------------------------------------\n-------------------------------------\n| rollout/              |           |\n|    ep_len_mean        | 373       |\n|    ep_rew_mean        | -10.6     |\n| time/                 |           |\n|    fps                | 313       |\n|    iterations         | 14700     |\n|    time_elapsed       | 234       |\n|    total_timesteps    | 73500     |\n| train/                |           |\n|    entropy_loss       | -0.00031  |\n|    explained_variance | 0.307     |\n|    learning_rate      | 0.0007    |\n|    n_updates          | 14699     |\n|    policy_loss        | -3.72e-05 |\n|    value_loss         | 3.46      |\n-------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 379      |\n|    ep_rew_mean        | -8.46    |\n| time/                 |          |\n|    fps                | 313      |\n|    iterations         | 14800    |\n|    time_elapsed       | 235      |\n|    total_timesteps    | 74000    |\n| train/                |          |\n|    entropy_loss       | -0.0187  |\n|    explained_variance | 0.0503   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14799    |\n|    policy_loss        | 0.00213  |\n|    value_loss         | 0.795    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 381      |\n|    ep_rew_mean        | -3.17    |\n| time/                 |          |\n|    fps                | 313      |\n|    iterations         | 14900    |\n|    time_elapsed       | 237      |\n|    total_timesteps    | 74500    |\n| train/                |          |\n|    entropy_loss       | -0.443   |\n|    explained_variance | 0.693    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14899    |\n|    policy_loss        | -0.323   |\n|    value_loss         | 1.29     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 382      |\n|    ep_rew_mean        | 0.903    |\n| time/                 |          |\n|    fps                | 313      |\n|    iterations         | 15000    |\n|    time_elapsed       | 238      |\n|    total_timesteps    | 75000    |\n| train/                |          |\n|    entropy_loss       | -0.663   |\n|    explained_variance | 0.184    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 14999    |\n|    policy_loss        | 1.78     |\n|    value_loss         | 13.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 382      |\n|    ep_rew_mean        | 0.903    |\n| time/                 |          |\n|    fps                | 313      |\n|    iterations         | 15100    |\n|    time_elapsed       | 240      |\n|    total_timesteps    | 75500    |\n| train/                |          |\n|    entropy_loss       | -1.11    |\n|    explained_variance | 0.246    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15099    |\n|    policy_loss        | -0.309   |\n|    value_loss         | 1.69     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 390      |\n|    ep_rew_mean        | 0.971    |\n| time/                 |          |\n|    fps                | 312      |\n|    iterations         | 15200    |\n|    time_elapsed       | 242      |\n|    total_timesteps    | 76000    |\n| train/                |          |\n|    entropy_loss       | -0.505   |\n|    explained_variance | 0.698    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15199    |\n|    policy_loss        | 0.336    |\n|    value_loss         | 1.69     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 390      |\n|    ep_rew_mean        | 0.971    |\n| time/                 |          |\n|    fps                | 312      |\n|    iterations         | 15300    |\n|    time_elapsed       | 244      |\n|    total_timesteps    | 76500    |\n| train/                |          |\n|    entropy_loss       | -0.0675  |\n|    explained_variance | 0.00248  |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15299    |\n|    policy_loss        | 0.823    |\n|    value_loss         | 0.441    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 394      |\n|    ep_rew_mean        | 3.61     |\n| time/                 |          |\n|    fps                | 312      |\n|    iterations         | 15400    |\n|    time_elapsed       | 246      |\n|    total_timesteps    | 77000    |\n| train/                |          |\n|    entropy_loss       | -0.888   |\n|    explained_variance | 0.426    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15399    |\n|    policy_loss        | -0.681   |\n|    value_loss         | 1.21     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 399      |\n|    ep_rew_mean        | 6.22     |\n| time/                 |          |\n|    fps                | 312      |\n|    iterations         | 15500    |\n|    time_elapsed       | 247      |\n|    total_timesteps    | 77500    |\n| train/                |          |\n|    entropy_loss       | -0.746   |\n|    explained_variance | 0.417    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15499    |\n|    policy_loss        | 0.469    |\n|    value_loss         | 1.24     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 399      |\n|    ep_rew_mean        | 6.22     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 15600    |\n|    time_elapsed       | 250      |\n|    total_timesteps    | 78000    |\n| train/                |          |\n|    entropy_loss       | -0.896   |\n|    explained_variance | -0.297   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15599    |\n|    policy_loss        | 1.07     |\n|    value_loss         | 7.3      |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 407      |\n|    ep_rew_mean        | 7.64     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 15700    |\n|    time_elapsed       | 251      |\n|    total_timesteps    | 78500    |\n| train/                |          |\n|    entropy_loss       | -1.06    |\n|    explained_variance | -1.2     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15699    |\n|    policy_loss        | -2.49    |\n|    value_loss         | 13.4     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 407      |\n|    ep_rew_mean        | 7.64     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 15800    |\n|    time_elapsed       | 253      |\n|    total_timesteps    | 79000    |\n| train/                |          |\n|    entropy_loss       | -0.728   |\n|    explained_variance | 0.0107   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15799    |\n|    policy_loss        | 0.977    |\n|    value_loss         | 3        |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 415      |\n|    ep_rew_mean        | 9.76     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 15900    |\n|    time_elapsed       | 255      |\n|    total_timesteps    | 79500    |\n| train/                |          |\n|    entropy_loss       | -0.648   |\n|    explained_variance | 0.85     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15899    |\n|    policy_loss        | 0.558    |\n|    value_loss         | 8.27     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 416      |\n|    ep_rew_mean        | 9.71     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 16000    |\n|    time_elapsed       | 256      |\n|    total_timesteps    | 80000    |\n| train/                |          |\n|    entropy_loss       | -0.417   |\n|    explained_variance | 0.541    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 15999    |\n|    policy_loss        | -1.69    |\n|    value_loss         | 1.46     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 416      |\n|    ep_rew_mean        | 9.71     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 16100    |\n|    time_elapsed       | 258      |\n|    total_timesteps    | 80500    |\n| train/                |          |\n|    entropy_loss       | -0.862   |\n|    explained_variance | 0.229    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16099    |\n|    policy_loss        | -0.681   |\n|    value_loss         | 2.69     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 424      |\n|    ep_rew_mean        | 9.07     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 16200    |\n|    time_elapsed       | 260      |\n|    total_timesteps    | 81000    |\n| train/                |          |\n|    entropy_loss       | -0.535   |\n|    explained_variance | 0.987    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16199    |\n|    policy_loss        | 2.61     |\n|    value_loss         | 3.42     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 428      |\n|    ep_rew_mean        | 10.5     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 16300    |\n|    time_elapsed       | 262      |\n|    total_timesteps    | 81500    |\n| train/                |          |\n|    entropy_loss       | -0.97    |\n|    explained_variance | 0.702    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16299    |\n|    policy_loss        | 1.37     |\n|    value_loss         | 1.91     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 428      |\n|    ep_rew_mean        | 10.5     |\n| time/                 |          |\n|    fps                | 311      |\n|    iterations         | 16400    |\n|    time_elapsed       | 263      |\n|    total_timesteps    | 82000    |\n| train/                |          |\n|    entropy_loss       | -0.218   |\n|    explained_variance | 0.43     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16399    |\n|    policy_loss        | -0.0835  |\n|    value_loss         | 1.93     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 435      |\n|    ep_rew_mean        | 11.3     |\n| time/                 |          |\n|    fps                | 310      |\n|    iterations         | 16500    |\n|    time_elapsed       | 265      |\n|    total_timesteps    | 82500    |\n| train/                |          |\n|    entropy_loss       | -0.333   |\n|    explained_variance | -1.09    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16499    |\n|    policy_loss        | -1.34    |\n|    value_loss         | 28.3     |\n------------------------------------\n-------------------------------------\n| rollout/              |           |\n|    ep_len_mean        | 435       |\n|    ep_rew_mean        | 11.3      |\n| time/                 |           |\n|    fps                | 310       |\n|    iterations         | 16600     |\n|    time_elapsed       | 267       |\n|    total_timesteps    | 83000     |\n| train/                |           |\n|    entropy_loss       | -0.000482 |\n|    explained_variance | 0.00619   |\n|    learning_rate      | 0.0007    |\n|    n_updates          | 16599     |\n|    policy_loss        | 2.62e-06  |\n|    value_loss         | 0.0116    |\n-------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 442      |\n|    ep_rew_mean        | 11.2     |\n| time/                 |          |\n|    fps                | 310      |\n|    iterations         | 16700    |\n|    time_elapsed       | 268      |\n|    total_timesteps    | 83500    |\n| train/                |          |\n|    entropy_loss       | -0.835   |\n|    explained_variance | 0.806    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16699    |\n|    policy_loss        | 0.374    |\n|    value_loss         | 0.989    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 437      |\n|    ep_rew_mean        | 15.9     |\n| time/                 |          |\n|    fps                | 310      |\n|    iterations         | 16800    |\n|    time_elapsed       | 270      |\n|    total_timesteps    | 84000    |\n| train/                |          |\n|    entropy_loss       | -0.499   |\n|    explained_variance | -0.112   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16799    |\n|    policy_loss        | -4.18    |\n|    value_loss         | 15.6     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 437      |\n|    ep_rew_mean        | 15.9     |\n| time/                 |          |\n|    fps                | 310      |\n|    iterations         | 16900    |\n|    time_elapsed       | 272      |\n|    total_timesteps    | 84500    |\n| train/                |          |\n|    entropy_loss       | -0.753   |\n|    explained_variance | -0.924   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16899    |\n|    policy_loss        | 0.168    |\n|    value_loss         | 0.388    |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 446      |\n|    ep_rew_mean        | 14.4     |\n| time/                 |          |\n|    fps                | 309      |\n|    iterations         | 17000    |\n|    time_elapsed       | 274      |\n|    total_timesteps    | 85000    |\n| train/                |          |\n|    entropy_loss       | -0.551   |\n|    explained_variance | -0.182   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 16999    |\n|    policy_loss        | 0.685    |\n|    value_loss         | 7.11     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 450      |\n|    ep_rew_mean        | 16.8     |\n| time/                 |          |\n|    fps                | 309      |\n|    iterations         | 17100    |\n|    time_elapsed       | 276      |\n|    total_timesteps    | 85500    |\n| train/                |          |\n|    entropy_loss       | -0.323   |\n|    explained_variance | 0.0901   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17099    |\n|    policy_loss        | 0.00426  |\n|    value_loss         | 0.00391  |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 447      |\n|    ep_rew_mean        | 14.4     |\n| time/                 |          |\n|    fps                | 309      |\n|    iterations         | 17200    |\n|    time_elapsed       | 277      |\n|    total_timesteps    | 86000    |\n| train/                |          |\n|    entropy_loss       | -0.352   |\n|    explained_variance | 0.197    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17199    |\n|    policy_loss        | -2.16    |\n|    value_loss         | 3.62     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 447      |\n|    ep_rew_mean        | 14.4     |\n| time/                 |          |\n|    fps                | 308      |\n|    iterations         | 17300    |\n|    time_elapsed       | 280      |\n|    total_timesteps    | 86500    |\n| train/                |          |\n|    entropy_loss       | -0.701   |\n|    explained_variance | -0.198   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17299    |\n|    policy_loss        | 0.126    |\n|    value_loss         | 2.17     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 454      |\n|    ep_rew_mean        | 15.5     |\n| time/                 |          |\n|    fps                | 308      |\n|    iterations         | 17400    |\n|    time_elapsed       | 282      |\n|    total_timesteps    | 87000    |\n| train/                |          |\n|    entropy_loss       | -0.522   |\n|    explained_variance | -0.248   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17399    |\n|    policy_loss        | 0.444    |\n|    value_loss         | 1.02     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 456      |\n|    ep_rew_mean        | 17.4     |\n| time/                 |          |\n|    fps                | 308      |\n|    iterations         | 17500    |\n|    time_elapsed       | 283      |\n|    total_timesteps    | 87500    |\n| train/                |          |\n|    entropy_loss       | -0.859   |\n|    explained_variance | 0.34     |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17499    |\n|    policy_loss        | -1.49    |\n|    value_loss         | 3.31     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 456      |\n|    ep_rew_mean        | 17.4     |\n| time/                 |          |\n|    fps                | 307      |\n|    iterations         | 17600    |\n|    time_elapsed       | 285      |\n|    total_timesteps    | 88000    |\n| train/                |          |\n|    entropy_loss       | -0.855   |\n|    explained_variance | -0.184   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17599    |\n|    policy_loss        | -0.765   |\n|    value_loss         | 4.98     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 466      |\n|    ep_rew_mean        | 21       |\n| time/                 |          |\n|    fps                | 307      |\n|    iterations         | 17700    |\n|    time_elapsed       | 287      |\n|    total_timesteps    | 88500    |\n| train/                |          |\n|    entropy_loss       | -0.953   |\n|    explained_variance | 0.381    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17699    |\n|    policy_loss        | -1.37    |\n|    value_loss         | 4.17     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 466      |\n|    ep_rew_mean        | 21       |\n| time/                 |          |\n|    fps                | 307      |\n|    iterations         | 17800    |\n|    time_elapsed       | 289      |\n|    total_timesteps    | 89000    |\n| train/                |          |\n|    entropy_loss       | -0.86    |\n|    explained_variance | -0.216   |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17799    |\n|    policy_loss        | -0.727   |\n|    value_loss         | 1.99     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 474      |\n|    ep_rew_mean        | 20.3     |\n| time/                 |          |\n|    fps                | 307      |\n|    iterations         | 17900    |\n|    time_elapsed       | 291      |\n|    total_timesteps    | 89500    |\n| train/                |          |\n|    entropy_loss       | -0.556   |\n|    explained_variance | -0.24    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17899    |\n|    policy_loss        | -0.704   |\n|    value_loss         | 6.34     |\n------------------------------------\n------------------------------------\n| rollout/              |          |\n|    ep_len_mean        | 474      |\n|    ep_rew_mean        | 20.3     |\n| time/                 |          |\n|    fps                | 307      |\n|    iterations         | 18000    |\n|    time_elapsed       | 292      |\n|    total_timesteps    | 90000    |\n| train/                |          |\n|    entropy_loss       | -0.782   |\n|    explained_variance | 0.211    |\n|    learning_rate      | 0.0007   |\n|    n_updates          | 17999    |\n|    policy_loss        | -1.54    |\n|    value_loss         | 1.59     |\n------------------------------------\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767980049
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = A2C.load(f'{env_name}-{model_name}')"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767586267
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def record_trained_model(model): \r\n",
        "    episodes = 10\r\n",
        "    env = gym.make(env_name)\r\n",
        "    env = RecordVideo(env, f'{env_name}-{model_name}-video', episode_trigger=lambda _: True)  \r\n",
        "    \r\n",
        "    for episode in range(episodes): \r\n",
        "        observation = env.reset()\r\n",
        "        done = False \r\n",
        "        score = 0 \r\n",
        "        while not done: \r\n",
        "            action, _states = model.predict(observation)\r\n",
        "            observation, reward, done, info = env.step(action)\r\n",
        "            score += reward \r\n",
        "        print(f'Episode={episode+1} Score:{score}')\r\n",
        "    env.close()\r\n",
        "\r\n",
        "  "
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767994210
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "record_trained_model(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/gym/wrappers/record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpucomputer/code/Users/fkhan/RL-reserach/LunarLander-v2-a2c-video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n  logger.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Episode=1 Score:-66.75733643304083\nEpisode=2 Score:281.3121662970005\nEpisode=3 Score:271.07596534873153\nEpisode=4 Score:131.7634937686478\nEpisode=5 Score:74.02422871995887\nEpisode=6 Score:65.87009071613258\nEpisode=7 Score:8.963145650033425\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672767598998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}